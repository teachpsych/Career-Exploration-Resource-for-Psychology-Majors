{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code works, do experiments below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// careers can be entered with a bachelor’s degree (highlighted in BLUE), \n",
    "// and those whose careers require a graduate degree (highlighted in GREEN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from docx import Document\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "# Function to check if run is highlighted and get the highlight color\n",
    "def get_highlight_color(run):\n",
    "    highlight_elements = run.element.xpath('.//w:highlight')\n",
    "    if highlight_elements:\n",
    "        highlight_element = highlight_elements[0]\n",
    "        color = highlight_element.get(qn('w:val'))\n",
    "        return color\n",
    "    return None\n",
    "\n",
    "def read_docx(file_path, start_line, end_line):\n",
    "    doc = Document(file_path)\n",
    "    lines = []\n",
    "    line_count = 0\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if start_line <= line_count < end_line:\n",
    "            para_text = paragraph.text.strip()\n",
    "            highlight_color = None\n",
    "            for run in paragraph.runs:\n",
    "                color = get_highlight_color(run)\n",
    "                if color:\n",
    "                    highlight_color = color  # Capture the first highlighted color in the paragraph\n",
    "                    break\n",
    "            lines.append((para_text, highlight_color))  # Store line and highlight color as a tuple\n",
    "        line_count += 1\n",
    "    return lines\n",
    "\n",
    "def parse_lines(lines):\n",
    "    url_pattern = re.compile(r'https?://\\S+')\n",
    "    youtube_pattern = re.compile(r'(https?://(?:www\\.)?youtube\\.com/watch\\?v=[\\w-]+|https?://(?:www\\.)?youtu\\.be/[\\w-]+)')\n",
    "    data = []\n",
    "    current_main_category = None\n",
    "    current_job = None\n",
    "    jobs = {}\n",
    "\n",
    "    for line, highlight_color in lines:\n",
    "        youtube_match = youtube_pattern.search(line)\n",
    "        if youtube_match:\n",
    "            # Extract the YouTube URL\n",
    "            youtube_url = youtube_match.group()\n",
    "            video_id = re.search(r'(?:v=|youtu\\.be/)([\\w-]+)', youtube_url).group(1)\n",
    "            \n",
    "            # Store the video ID instead of the iframe HTML\n",
    "            if current_job and current_job in jobs:\n",
    "                jobs[current_job]['videos'].append({\n",
    "                    'video_id': video_id,  # Store only the video ID\n",
    "                    'url': youtube_url      # Optionally store the original URL\n",
    "                })\n",
    "        elif url_pattern.search(line):\n",
    "            # Extract the URL\n",
    "            url_match = url_pattern.search(line)\n",
    "            url = url_match.group()\n",
    "            \n",
    "            # Extract the category (everything before the URL)\n",
    "            category = line[:url_match.start()].strip()\n",
    "\n",
    "            if current_job and current_job in jobs:\n",
    "                jobs[current_job]['links'].append({\n",
    "                    'url': url,\n",
    "                    'category': category\n",
    "                })\n",
    "        elif line.lower().startswith(\"undefined\"):\n",
    "            # Skip lines starting with \"undefined\"\n",
    "            continue\n",
    "        else:\n",
    "            if current_main_category is None:\n",
    "                # Set the main category\n",
    "                current_main_category = line\n",
    "            elif current_job is None:\n",
    "                # Set the job title (sub_category)\n",
    "                current_job = line\n",
    "                jobs[current_job] = {\n",
    "                    'links': [],\n",
    "                    'videos': [],\n",
    "                    'degree_required': \"Bachelor's\" if highlight_color == 'cyan' else \"Graduate Degree\" if highlight_color == 'green' else ''\n",
    "                }\n",
    "            else:\n",
    "                # Handle a new main category if a new line appears\n",
    "                if line.strip() == \"\":\n",
    "                    if current_main_category:\n",
    "                        # Save the current main category and its jobs\n",
    "                        data.append({\n",
    "                            'main_category': current_main_category,\n",
    "                            'jobs': jobs\n",
    "                        })\n",
    "                        # Reset for the next main category\n",
    "                        current_main_category = None\n",
    "                        jobs = {}\n",
    "                        current_job = None\n",
    "                else:\n",
    "                    # If it's neither a URL nor an empty line, it might be a new job\n",
    "                    if current_job:\n",
    "                        # Make sure to add the current job to jobs before changing\n",
    "                        current_job = line\n",
    "                        jobs[current_job] = {\n",
    "                            'links': [],\n",
    "                            'videos': [],\n",
    "                            'degree_required': \"Bachelor's\" if highlight_color == 'cyan' else \"Graduate Degree\" if highlight_color == 'green' else ''\n",
    "                        }\n",
    "\n",
    "    # Handle the last main category and jobs if they exist\n",
    "    if current_main_category and jobs:\n",
    "        data.append({\n",
    "            'main_category': current_main_category,\n",
    "            'jobs': jobs\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_to_json(data, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def main(file_path, start_line, end_line, output_file):\n",
    "    lines = read_docx(file_path, start_line, end_line)\n",
    "    data = parse_lines(lines)\n",
    "    save_to_json(data, output_file)\n",
    "\n",
    "# Specify the file path and line range\n",
    "file_path = 'careers.docx'\n",
    "start_line = 171  # Starting line (inclusive)\n",
    "end_line = start_line + 3000  # Adjust the ending line as needed\n",
    "output_file = 'jobs.json'\n",
    "\n",
    "main(file_path, start_line, end_line, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// careers can be entered with a bachelor’s degree (highlighted in BLUE), \n",
    "// and those whose careers require a graduate degree (highlighted in GREEN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a site with jobs tables in json file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
